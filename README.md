# mixture_models
This toy example comes from https://www.youtube.com/watch?v=oHWNexYPFTY&t=1247s. The seminar speaker presents the model but does not explain it, so here is my attempt at doing so. Despite being a very simple toy example, it captures all the steps required to fit mixture models in STAN and can be adapted for zero inflated Poisson regression or other custom mixture models. I also show how to make posterior predictive simulations and calculate model likelihood for WAIC and model comparison.

## Background

We want to model the effect of a cat being present in a garden on the number of bird songs. We have data regarding the number of songs, but only data on whether we *observe* the cat rather than if the cat is actually *present* (cats are notoriously sneaky). Nevertheless we can still estimate the probability that the cat is *present*. This can be used to evaluate how good we are at spotting the cat, which is very useful in case we are working with real data regarding species presence or absence. The way to model this is with a mixture model. Mixture models combine mulitple likelihood functions, which in our example describe two possible scenarios: 1) the number of songs when the cat is not seen and not present, 2) the number of songs when the cat is not seen but actually present. This "combined likelihood" is simply the sum of the likelihood of each scenario weighted by the probability of that scenario, which is called "marginalizing". The way to implement this in STAN (lines 31 to 40) relies on conditioning on the observed data, such that the "mixture nature" of the model is only evident when we have to calculate the likelihood when the cat is not present. STAN user's guide on mixture models is great: https://mc-stan.org/docs/stan-users-guide/finite-mixtures.html. 

## Code

I first simulate whether the cat is present, then I simulate the data that could be gathered from an experiment: the number of songs and whether the cat is observed. Then I compile and fit the STAN model misterious_mixture.stan **only on the data - not on the presence of the cat** to see if I can recover the correct simulation parameter values.  I use the generated quantities block to make posterior predicitve simulations. For every parameter combination given by the MCMC sampler, the generated quantities block simulates the observed data (number of songs and whether cat is observed), and also cat presence. The fact that we can use the model to simulate an unknown quantity such as cat presence is useful for more complex models such as Hidden Markov Models, where our main interest is to known a hidden individual state which we cannot observe directly. In the generated quantities block I also store the likelihood of every observation. This is used to calculate the log pointwise posterior probability density (lppd), the counterpart of the frequentist likelihood that considers the enitre parameter distribution rather than just the one associated with the maximum likelihood. From the lppd, we can calculate the WAIC. I use the custom function of the loo package to do so because the lppd includes a sum of probabilities: this is computationally difficult to calculate when working with log probabilities. Coincidently, the numerically stable way to calculate the lppd includes the same type of custom function used in the STAN mixture model to marginalize (through a weighted sum of probabilites) over multiple likelihood functions (log_sum_exp()). 

You can try to adapt the code to make a zero inflated Poisson regression model where you model the abbundance of individuals with vegetation cover, considering that sometimes you miss all the individuals even though some are present (nevermind if it is not very realistic). If you want, make one model where the probability of missing the individuals is also influenced by vegetation cover.
